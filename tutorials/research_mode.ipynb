{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Research Mode\n",
    "\n",
    "In this tutorial IPython Notebook, we will cover the more advanced functionalities of Gaggle. In particular, this is for users that are familiar with Pytorch and are looking for research-grade custom capabilities.\n",
    "\n",
    "To do so, we will go over the different modules of gaggle, their purpose and how they should be interacted with. In the introductory tutorial, we covered the supervisor, which is essentially a wrapper for most of gaggle's functionalities for beginners. Now we'll first look at a basic training script and the different arguments classes that are used to implement smooth and easy config file support.\n",
    "\n",
    "Below is an overview of the topic covered\n",
    "- [Arguments and Training Script](#args)\n",
    "- [Config File](#config_file)\n",
    "- [Problem](#problem)\n",
    "- [Classification Problem](#problem)\n",
    "- [Reinforcement Learning](#rl)\n",
    "- [Leap Problems](#leap)\n",
    "- [GA](#ga)\n",
    "- [Population Manager](#population_manager)\n",
    "- [Selection](#selection)\n",
    "- [Crossover](#crossover)\n",
    "- [Mutation](#mutation)\n",
    "- [Registering Custom Operators](#registering_custom_operators)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Arguments and Training Script <a class=\"anchor\" id=\"args\"></a>\n",
    "\n",
    "Below is a basic example training script that can also be found in examples folder of the gaggle github repository as train.py."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from gaggle.ga import GA\n",
    "from gaggle.ga.ga_factory import GAFactory\n",
    "from gaggle.arguments.config_args import parse_args\n",
    "\n",
    "\n",
    "def train():\n",
    "    \"\"\" Train a model from scratch on a data. \"\"\"\n",
    "    outdir_args, sys_args, individual_args, problem_args, ga_args, config_args = parse_args()\n",
    "    if config_args.exists():\n",
    "        outdir_args, sys_args, individual_args, problem_args, ga_args = config_args.get_args()\n",
    "\n",
    "    trainer: GA = GAFactory.from_ga_args(ga_args=ga_args, problem_args=problem_args, sys_args=sys_args,\n",
    "                                         outdir_args=outdir_args, individual_args=individual_args)\n",
    "    trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's first focus on line 8. 'outdir_args, sys_args, individual_args, problem_args, ga_args, config_args = parse_args()'.\n",
    "This line does two things, it generates the different argument objects our framework uses, you can find a more thorough description of them in the documentation. It also reads whatever command line arguments that were set when running the script and updates the relevant arguments with the values mentioned in te command line.\n",
    "This allows to run the code from the command line without a config file like you would a standard python script.\n",
    "\n",
    "Then for line 9 and 10, it checks if the config_path argument was set in the command line. If that's the case, it overwrites the arguments with whatever was set in the config file. Beware, this means that any other command line argument that was passed also gets overwritten and therefore needs to be specified in the config file instead.\n",
    "\n",
    "Finally, in lines 12 and 14, we initialize the GA by passing it the generated argument objects. The GA will take care of setting up the entire pipeline according to the given arguments. Line 14 tells the GA to start training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Config File <a id='config_file'></a>\n",
    "\n",
    "We'll now see how to structure a standard experiment config file for our framework. Below is a simple example config file to train a population of models on the mnist dataset. This should be stored in a .yml file. In this case it can be train_mnist_lenet.yml for example."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<code>\n",
    "individual_args:\n",
    "  model_name: lenet\n",
    "\n",
    "problem_args:\n",
    "  problem_name: MNIST\n",
    "  batch_size: 50000\n",
    "  eval_batch_size: 10000\n",
    "\n",
    "ga_args:\n",
    "  population_size: 200\n",
    "  num_parents: 200\n",
    "  crossover: uniform\n",
    "  selection: weighted\n",
    "  mutation: normal\n",
    "  mutation_std: 0.02\n",
    "  mutation_chance: 0.01\n",
    "  parent_survival_rate: 0.5\n",
    "  elitism: 0.1\n",
    "  generations: 1000\n",
    "  eval_every_generation: 500\n",
    "\n",
    "sys_args:\n",
    "  device: cuda\n",
    "\n",
    "output_dir:\n",
    "  root: ../experiments   # creates this root directory for the outputs\n",
    "  name: mnist            # the name of the experiment (optional)\n",
    "</code>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now run the original training script with the above config by just running the following:\n",
    "\n",
    "<pre><code>python3 train.py --config_path ./train_mnist_lenet.yml </code></pre>\n",
    "\n",
    "Now that we've covered how to setup a basic training script and a configuration file for it, we'll dive deeper into how gaggle works on how to customize it for your own research/experimentation needs.\n",
    "To that purpose, we'll first cover the Problem module/class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Problem\n",
    "<a class=\"anchor\" id='problem'></a>\n",
    "\n",
    "The problem module and class encompass everything that represents the objective/fitness function that needs to be solved. From the simple Rastrigin benchmark function (as seen in the introductory notebook) to more complex Image Classification tasks like MNIST or CIFAR10.\n",
    "\n",
    "All in all, Gaggle's problems can be summarized in 4 different types:\n",
    "- classification\n",
    "- rl (reinforcement learning)\n",
    "- leap (other GA framework whose problems we also support)\n",
    "- custom\n",
    "\n",
    "We'll therefore first cover how to create and register one of each problem in gaggle's framework.\n",
    "\n",
    "### Classification Problem\n",
    "\n",
    "Below, I'll put the classification problem code (as of version 0.0.1) so we can go through it together and see what does what and what needs to be modified to implement a custom problem."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from gaggle.problem.problem import Problem\n",
    "from gaggle.population import Individual, PopulationManager\n",
    "from gaggle.arguments import ProblemArgs, SysArgs\n",
    "from gaggle.problem.dataset import DatasetFactory\n",
    "from gaggle.utils.smooth_value import SmoothedValue\n",
    "from gaggle.utils.metrics import accuracy\n",
    "import torch\n",
    "\n",
    "\n",
    "class ClassificationProblem(Problem):\n",
    "    \"\"\"A Problem that represents a standard Machine Learning classification problem. It stores the associated\n",
    "    training and validation dataset. Population evaluation optimized for GPU by default to speed up training.\n",
    "    To create a classification problem with a custom dataset, register said dataset in the DatasetFactory.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, problem_args: ProblemArgs = None, sys_args: SysArgs = None):\n",
    "        super(ClassificationProblem, self).__init__(problem_args, sys_args)\n",
    "        self.train_dataset = DatasetFactory.from_problem_args(problem_args, train=True)\n",
    "        self.train_data, self.train_transforms = self.train_dataset.get_data_and_transform()\n",
    "        if self.problem_args.batch_size == -1:\n",
    "            # this means use the entire dataset without batching\n",
    "            self.problem_args.batch_size = self.train_data[0].size(0)\n",
    "\n",
    "        if self.problem_args.batch_size == self.train_data[0].size(0):\n",
    "            # we move everything to the gpu and let it live on the gpu\n",
    "            print(f\"Batching is not necessary, will store the entire data on device: {sys_args.device}\")\n",
    "            self.train_data = (self.train_data[0].to(self.sys_args.device), self.train_data[1].to(\n",
    "                self.sys_args.device))\n",
    "\n",
    "        self.eval_dataset = DatasetFactory.from_problem_args(problem_args, train=False)\n",
    "        self.eval_data, self.eval_transforms = self.eval_dataset.get_data_and_transform()\n",
    "        if self.problem_args.eval_batch_size == -1:\n",
    "            self.problem_args.eval_batch_size = self.eval_data[0].size(0)\n",
    "\n",
    "        self.current_batch = None\n",
    "        self.fitness_function = accuracy\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate_population(self, population_manager: PopulationManager,\n",
    "                            use_freshness: bool = True, update_manager: bool = True, train: bool = True,\n",
    "                            *args, **kwargs) -> dict[int: float]:\n",
    "        \"\"\"Population evaluation optimized for GPU by default to speed up training. Should only be modified if\n",
    "        specific custom behavior is desired. It is usually not recommend to modify this function.\n",
    "\n",
    "        Args:\n",
    "            population_manager:\n",
    "            use_freshness:\n",
    "            update_manager:\n",
    "            train:\n",
    "            *args:\n",
    "            **kwargs:\n",
    "\n",
    "        Returns:\n",
    "            The dictionary of individual fitnesses\n",
    "        \"\"\"\n",
    "        all_data = self.train_data if train else self.eval_data\n",
    "        transforms = self.train_transforms if train else self.eval_transforms\n",
    "        batch_size = self.problem_args.batch_size if train else self.problem_args.eval_batch_size\n",
    "        num_inputs = all_data[0].size(0)\n",
    "\n",
    "        fitness = {}\n",
    "        for i in range(population_manager.population_size):\n",
    "            if population_manager.is_fresh(i) and use_freshness:\n",
    "                fitness[i] = SmoothedValue()\n",
    "            elif not use_freshness:\n",
    "                fitness[i] = SmoothedValue()\n",
    "\n",
    "        num_batches = num_inputs // batch_size\n",
    "        rest = num_inputs % batch_size\n",
    "        for j in range(num_batches):\n",
    "            data = all_data[0][j * batch_size:(j + 1) * batch_size].to(self.sys_args.device)\n",
    "            data = transforms(data)\n",
    "            targets = all_data[1][j * batch_size:(j + 1) * batch_size].to(self.sys_args.device)\n",
    "            self.current_batch = (data, targets)\n",
    "            for k in list(fitness.keys()):\n",
    "                fitness[k].update(self.evaluate(population_manager.get_individual(k), *args, **kwargs), n=batch_size)\n",
    "\n",
    "        if rest > 0:\n",
    "            data = transforms(all_data[0][-rest:].to(self.sys_args.device))\n",
    "            targets = all_data[1][-rest:].to(self.sys_args.device)\n",
    "            self.current_batch = (data, targets)\n",
    "            for l in list(fitness.keys()):\n",
    "                fitness[l].update(self.evaluate(population_manager.get_individual(l), *args, **kwargs), n=batch_size)\n",
    "\n",
    "        for m in list(fitness.keys()):\n",
    "            fitness[m] = fitness[m].global_avg\n",
    "            if update_manager:\n",
    "                population_manager.set_individual_fitness(m, fitness[m])\n",
    "                if use_freshness:\n",
    "                    population_manager.set_freshness(m, False)\n",
    "\n",
    "        if train and use_freshness:\n",
    "            return population_manager.get_fitness()\n",
    "\n",
    "        return fitness\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, individual: Individual, train: bool = True, *args, **kwargs) -> float:\n",
    "        \"\"\"Evaluates an individual on the current batch of data.\n",
    "\n",
    "        Args:\n",
    "            individual:\n",
    "            train: whether we are currently training or performing an inference.\n",
    "            *args:\n",
    "            **kwargs:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        if train:\n",
    "            individual.train()\n",
    "        else:\n",
    "            individual.eval()\n",
    "        x, y = self.current_batch\n",
    "        x, y = x.to(self.sys_args.device), y.to(self.sys_args.device)\n",
    "        y_pred = individual(x)\n",
    "        return self.fitness_function(y_pred, y).cpu().item()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A ClassificationProblem stores the datasets that are used to perform classification and it gets them from the DatasetFactory as seen in line 18 and 30.\n",
    "By default, the fitness_function for the classification is the accuracy metric, but this can be easily changed as we'll see below.\n",
    "\n",
    "First let's say we have a custom dataset, and we want to create a ClassificationProblem out of it for a model to evolve to solve."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CIFAR10', 'MNIST']\n",
      "['CIFAR10', 'MNIST', 'custom_dataset']\n"
     ]
    }
   ],
   "source": [
    "from gaggle.problem.dataset import DataWrapper, Dataset, DatasetFactory\n",
    "\n",
    "def build_dataset(train: bool = True):\n",
    "    if train:\n",
    "        # Train dataset\n",
    "        train_data = torch.rand((50, 3, 32, 32))\n",
    "        train_target = torch.randint(low=0, high=10, size=(50, 10)).to(torch.float)  # generating labels\n",
    "\n",
    "        # we wrap the data and targets to create a dataset like object, for users familiar with pytorch, this is similar to a TensorDataset\n",
    "        train_dataset = DataWrapper(data=train_data, targets=train_target)\n",
    "        return train_dataset\n",
    "    else:\n",
    "        # Test dataset\n",
    "        test_data = torch.rand((100, 3, 32, 32))\n",
    "        test_target = torch.randint(low=0, high=10, size=(500, 10)).to(torch.float)  # generating labels\n",
    "\n",
    "        test_dataset = DataWrapper(data=test_data, targets=test_target)\n",
    "        return test_dataset\n",
    "\n",
    "# We can now create our custom dataset\n",
    "# any dataset always needs at least a problem args object, whether it is train or test and a sys args object.\n",
    "# all the default functions we need will already be setup since we inherit from our Dataset class. So all we need to do is specify what the dataset attribute is.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, problem_args: ProblemArgs = None, train: bool = True, sys_args: SysArgs = None):\n",
    "        super(CustomDataset, self).__init__(problem_args, train, sys_args)\n",
    "        self.dataset = build_dataset(train)\n",
    "\n",
    "\n",
    "# now that our custom dataset is finally built, all we need to do is register it with our DatasetFactory class so that it can be built automatically.\n",
    "# to register it, we need to give it a unique name, we can see what are the current registered datasets:\n",
    "print(DatasetFactory.get_keys())\n",
    "\n",
    "# for now we'll set its name to custom\n",
    "key_name = \"custom_dataset\"\n",
    "\n",
    "DatasetFactory.update(key=key_name, dataset=CustomDataset)  # make sure to pass the uninitialized class as the dataset gets re-initialized at runtime for both the testing and training datasets.\n",
    "\n",
    "print(DatasetFactory.get_keys())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code above allows us to introduce a new custom dataset to our framework, now what if we want to change how the ClassificationProblem behaves. For example, we want to change the fitness function, although what I will showcase applies to any other significant change we want to make to the class' behavior.\n",
    "\n",
    "So first, we want to create a new problem class. We want to inherit the behavior of the ClassificationProblem."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's change the fitness function to a new function. Let's take for example Pytorch's CrossEntropyLoss function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CustomClassificationProblem(ClassificationProblem):\n",
    "    def __init__(self, problem_args: ProblemArgs = None, sys_args: SysArgs = None):\n",
    "        super(CustomClassificationProblem, self).__init__(problem_args, sys_args)\n",
    "        self.fitness_function = nn.CrossEntropyLoss()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we want to register this new problem to our framework, so we can use it with our original training script.\n",
    "This will also allow us to explore a second type of problem at the same time, custom problems.\n",
    "\n",
    "The main function we'll use for this is:\n",
    "<code>ProblemFactory.register_problem</code>\n",
    "\n",
    "It takes in 3 arguments:\n",
    "- problem_type: (str) the type of problem to register. It has to be one of the types within <pre><code>ProblemFactory.registrable_problems</code></pre>\n",
    "- problem_name: (str) the name that we want to give our problem. It has to be unique and not taken already by any of the other problems in any of the other problem types. This also includes custom dataset names registered through the DatasetFactory as the ProblemFactory scans the DatasetFactory to generate the classification problems.\n",
    "- problem: (Callable - Ideally unintialized Problem object) the actual problem class that will get instantiated when problem_name is requested\n",
    "- If any initialization time arguments are required to run your problem, they can be passed as *args and or **kwargs to the register_problem function.\n",
    "\n",
    "We can now register the problem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classification': {'CIFAR10': <class 'gaggle.problem.dataset.base_datasets.cifar10.CIFAR10'>, 'MNIST': <class 'gaggle.problem.dataset.base_datasets.mnist.MNIST'>, 'custom_dataset': <class '__main__.CustomDataset'>}, 'rl': {'cartpole': <gaggle.problem.environment.environment_factory.GymWrapper object at 0x7faacb63f730>}, 'leap': {}, 'custom': {}}\n",
      "{'classification': {'CIFAR10': <class 'gaggle.problem.dataset.base_datasets.cifar10.CIFAR10'>, 'MNIST': <class 'gaggle.problem.dataset.base_datasets.mnist.MNIST'>, 'custom_dataset': <class '__main__.CustomDataset'>}, 'rl': {'cartpole': <gaggle.problem.environment.environment_factory.GymWrapper object at 0x7faacb63f730>}, 'leap': {}, 'custom': {'custom_dataset_problem': (<class '__main__.CustomClassificationProblem'>, (), {})}}\n"
     ]
    }
   ],
   "source": [
    "from gaggle.problem import ProblemFactory\n",
    "\n",
    "# we cannot call it custom_dataset as this was already registered when we registered the custom Dataset\n",
    "print(ProblemFactory.problems)\n",
    "ProblemFactory.register_problem(\"custom\", \"custom_dataset_problem\", CustomClassificationProblem)\n",
    "print(ProblemFactory.problems)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we should be able to run\n",
    "<pre><code>python3 train.py --problem_name custom_dataset_problem</code></pre>\n",
    "(with the other additional other necessary parameters).\n",
    "\n",
    "### Reinforcement Learning\n",
    "<a id='rl'></a>\n",
    "\n",
    "For reinforcement learning problems, in particular OpenAI gym environment or any object whose class implements the Open AI environment API (reset, step, render etc...), we can use a process similar to custom datasets to register them"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classification': {'CIFAR10': <class 'gaggle.problem.dataset.base_datasets.cifar10.CIFAR10'>, 'MNIST': <class 'gaggle.problem.dataset.base_datasets.mnist.MNIST'>, 'custom_dataset': <class '__main__.CustomDataset'>}, 'rl': {'cartpole': <gaggle.problem.environment.environment_factory.GymWrapper object at 0x7faacb63f730>}, 'leap': {}, 'custom': {'custom_dataset_problem': (<class '__main__.CustomClassificationProblem'>, (), {})}}\n",
      "{'classification': {'CIFAR10': <class 'gaggle.problem.dataset.base_datasets.cifar10.CIFAR10'>, 'MNIST': <class 'gaggle.problem.dataset.base_datasets.mnist.MNIST'>, 'custom_dataset': <class '__main__.CustomDataset'>}, 'rl': {'cartpole': <gaggle.problem.environment.environment_factory.GymWrapper object at 0x7faacb63f730>, 'pendulum': <gaggle.problem.environment.environment_factory.GymWrapper object at 0x7faacb4ab550>}, 'leap': {}, 'custom': {'custom_dataset_problem': (<class '__main__.CustomClassificationProblem'>, (), {})}}\n"
     ]
    }
   ],
   "source": [
    "from gaggle.problem.environment import GymWrapper, EnvironmentFactory\n",
    "\n",
    "# the gym wrapper is a simple class that takes in the name of the gym environment and has its __call__ return the initialized gym environment.\n",
    "# If you are using your own environment that implements OpenAI gym environment's API, then you don't need to use the GymWrapper, just pass in the uninitialized class instead\n",
    "\n",
    "env = GymWrapper(\"Pendulum-v1\")\n",
    "\n",
    "print(ProblemFactory.problems)\n",
    "\n",
    "EnvironmentFactory.update(key=\"pendulum\", environment=env)\n",
    "\n",
    "print(ProblemFactory.problems)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now get the environment by setting <code>problem_name</code> to <code>pendulum</code>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LEAP Problems\n",
    "<a id='leap'></a>\n",
    "\n",
    "LEAP (or leap_ec) is another python library for Genetic Algorithms that provides a wide library of existing problems.\n",
    "In order to make it easy for people that are familiar to LEAP to use any one of their problems directly into our framework, we developed a conversion system that converts a LEAP problem into a Gaggle problem.\n",
    "\n",
    "We take for example below a fixed version of the RastriginProblem from the leap_ec library"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# first the necessary leap code, so you don't have to download the leap package just for this simple example\n",
    "from abc import ABC, abstractmethod\n",
    "from math import isclose, isnan\n",
    "import random\n",
    "\n",
    "\n",
    "class Problem(ABC):\n",
    "    \"\"\"\n",
    "        Abstract Base Class used to define problem definitions.\n",
    "\n",
    "        A `Problem` is in charge of two major parts of an EA's behavior:\n",
    "\n",
    "         1. Fitness evaluation (the `evaluate()` method)\n",
    "\n",
    "         2. Fitness comparision (the `worse_than()` and `equivalent()` methods)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self, phenome, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Evaluate the given individual based on its decoded phenome.\n",
    "\n",
    "        Practitioners *must* over-ride this member function.\n",
    "\n",
    "        Note that by default the individual comparison operators assume a\n",
    "        maximization problem; if this is a minimization problem, then just\n",
    "        negate the value when returning the fitness.\n",
    "\n",
    "        :param phenome:\n",
    "        :return: fitness\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def evaluate_multiple(self, phenomes):\n",
    "        \"\"\"Evaluate multiple individuals all at once, returning a list of fitness\n",
    "        values.\n",
    "\n",
    "        By default this just calls `self.evaluate()` multiple times.  Override this\n",
    "        if you need to, say, send a group of individuals off to parallel \"\"\"\n",
    "        return [ self.evaluate(p) for p in phenomes ]\n",
    "\n",
    "    @abstractmethod\n",
    "    def worse_than(self, first_fitness, second_fitness):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def equivalent(self, first_fitness, second_fitness):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "##############################\n",
    "# Class ScalarProblem\n",
    "##############################\n",
    "class ScalarProblem(Problem):\n",
    "    def __init__(self, maximize):\n",
    "        super().__init__()\n",
    "        self.maximize = maximize\n",
    "\n",
    "    def worse_than(self, first_fitness, second_fitness):\n",
    "        \"\"\"\n",
    "            Used in Individual.__lt__().\n",
    "\n",
    "            By default returns first_fitness < second_fitness if a maximization\n",
    "            problem, else first_fitness > second_fitness if a minimization\n",
    "            problem.  Please over-ride if this does not hold for your problem.\n",
    "\n",
    "            :return: true if the first individual is less fit than the second\n",
    "        \"\"\"\n",
    "        # NaN is assigned if the individual is non-viable, which can happen if\n",
    "        # an exception is thrown during evaluation. We consider NaN fitnesses to\n",
    "        # always be the worse possible with regards to ordering.\n",
    "        if isnan(first_fitness):\n",
    "            if isnan(second_fitness):\n",
    "                # both are nan, so to reduce bias flip a coin to arbitrarily\n",
    "                # select one that is worst.\n",
    "                return random.choice([True, False])\n",
    "            # Doesn't matter how awful second_fitness is, nan will already be\n",
    "            # considered worse.\n",
    "            return True\n",
    "        elif isnan(second_fitness):\n",
    "            # No matter how awful the first_fitness is, if it's not a NaN the\n",
    "            # NaN will always be worse\n",
    "            return False\n",
    "\n",
    "        # TODO If we accidentally pass an Individual in as first_ or second_fitness,\n",
    "        # TODO then this can result in an infinite loop.  Add some error\n",
    "        # handling for this.\n",
    "        if self.maximize:\n",
    "            return first_fitness < second_fitness\n",
    "        else:\n",
    "            return first_fitness > second_fitness\n",
    "\n",
    "    def equivalent(self, first_fitness, second_fitness):\n",
    "        \"\"\"\n",
    "            Used in Individual.__eq__().\n",
    "\n",
    "            By default returns first.fitness== second.fitness.  Please\n",
    "            over-ride if this does not hold for your problem.\n",
    "\n",
    "            :return: true if the first individual is equal to the second\n",
    "        \"\"\"\n",
    "\n",
    "        # Since we're comparing two real values, we need to be a little\n",
    "        # smarter about that.  This will return true if the difference\n",
    "        # between the two is within a small tolerance. This also handles\n",
    "        # NaNs, inf, and -inf.\n",
    "        if type(first_fitness) == float and type(second_fitness) == float:\n",
    "            return isclose(first_fitness, second_fitness)\n",
    "        else: # fallback if one or more are not floats\n",
    "            return first_fitness == second_fitness\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class RastriginProblem(ScalarProblem):\n",
    "    \"\"\" Modified to include negative fittness (LEAP had a bug)\n",
    "    \"\"\"\n",
    "    \"\"\" Standard bounds.\"\"\"\n",
    "    bounds = (-5.12, 5.12)\n",
    "    #NOTE we changed maximize to true\n",
    "    def __init__(self, a=10.0, maximize=True):\n",
    "        super().__init__(maximize)\n",
    "        self.a = a\n",
    "    def evaluate(self, phenome):\n",
    "        \"\"\"\n",
    "        Computes the function value from a real-valued list phenome:\n",
    "\n",
    "        >>> phenome = [1.0/12, 0]\n",
    "        >>> RastriginProblem().evaluate(phenome) # doctest: +ELLIPSIS\n",
    "        0.1409190406...\n",
    "\n",
    "        :param phenome: real-valued vector to be evaluated\n",
    "        :returns: its fitness\n",
    "        \"\"\"\n",
    "        #NOTE: We made negative as it is wrong\n",
    "        if isinstance(phenome, np.ndarray):\n",
    "            return - (self.a * len(phenome) + \\\n",
    "                np.sum(phenome ** 2 - self.a * np.cos(2 * np.pi * phenome)))\n",
    "        return self.a * \\\n",
    "            len(phenome) + sum([x ** 2 - self.a *\n",
    "                                np.cos(2 * np.pi * x) for x in phenome])\n",
    "\n",
    "    def worse_than(self, first_fitness, second_fitness):\n",
    "        return super().worse_than(first_fitness, second_fitness)\n",
    "\n",
    "    def __str__(self):\n",
    "        return RastriginProblem.__name__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we've defined the Leap Problem, we can import it into our framework"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classification': {'CIFAR10': <class 'gaggle.problem.dataset.base_datasets.cifar10.CIFAR10'>, 'MNIST': <class 'gaggle.problem.dataset.base_datasets.mnist.MNIST'>, 'custom_dataset': <class '__main__.CustomDataset'>}, 'rl': {'cartpole': <gaggle.problem.environment.environment_factory.GymWrapper object at 0x7faacb63f730>, 'pendulum': <gaggle.problem.environment.environment_factory.GymWrapper object at 0x7faacb4ab550>}, 'leap': {}, 'custom': {'custom_dataset_problem': (<class '__main__.CustomClassificationProblem'>, (), {})}}\n",
      "{'classification': {'CIFAR10': <class 'gaggle.problem.dataset.base_datasets.cifar10.CIFAR10'>, 'MNIST': <class 'gaggle.problem.dataset.base_datasets.mnist.MNIST'>, 'custom_dataset': <class '__main__.CustomDataset'>}, 'rl': {'cartpole': <gaggle.problem.environment.environment_factory.GymWrapper object at 0x7faacb63f730>, 'pendulum': <gaggle.problem.environment.environment_factory.GymWrapper object at 0x7faacb4ab550>}, 'leap': {'rastrigin': (<gaggle.problem.leap.leap_problem.RegistrableLeapProblem object at 0x7fab88263c70>, (), {})}, 'custom': {'custom_dataset_problem': (<class '__main__.CustomClassificationProblem'>, (), {})}}\n"
     ]
    }
   ],
   "source": [
    "print(ProblemFactory.problems)\n",
    "\n",
    "ProblemFactory.convert_and_register_leap_problem(problem_name=\"rastrigin\", leap_problem=RastriginProblem)\n",
    "\n",
    "print(ProblemFactory.problems)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And that's it!\n",
    "Now you can use that problem with Gaggle by specifying\n",
    "<code>problem_name</code> as <code>rastrigin</code>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GA\n",
    "<a id='ga'></a>\n",
    "\n",
    "Now that we've covered the Problem module/class we can move on to solving said problems! To do so, we'll look at the GA module/class.\n",
    "The GA class controls your overall evolution algorithm, how and when each operator is called as well as gathering and storing training metrics.\n",
    "Any custom implemented GA needs to inherit from the GA class (gaggle.ga.GA). There is only one abstract method to fill in: train.\n",
    "\n",
    "We'll go over a basic re-implementation of the SimpleGA with only its core components to see how things are pieced together:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from gaggle.arguments import GAArgs, SysArgs, IndividualArgs, ProblemArgs\n",
    "from gaggle.arguments.outdir_args import OutdirArgs\n",
    "from gaggle.population.population_manager import PopulationManager\n",
    "from gaggle.utils.special_print import print_dict_highlighted\n",
    "from gaggle.operators import Crossover, Mutation, Selection\n",
    "from gaggle.ga import GA\n",
    "from gaggle.problem import Problem\n",
    "\n",
    "\n",
    "class SimpleGA(GA):\n",
    "    r\"\"\"Implements a Simple Genetic Algorithm following Mitchell.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, population_manager: PopulationManager = None, ga_args: GAArgs = None,\n",
    "                 selection: Selection = None, crossover: Crossover = None, mutation: Mutation = None,\n",
    "                 problem_args: ProblemArgs = None, sys_args: SysArgs = None, outdir_args: OutdirArgs = None,\n",
    "                 individual_args: IndividualArgs = None, problem: Problem = None):\n",
    "        super(SimpleGA, self).__init__(population_manager, ga_args, selection, crossover, mutation, problem_args,\n",
    "                                       sys_args, outdir_args, individual_args, problem)\n",
    "        self.best = 0\n",
    "\n",
    "    def train_one_generation(self):\n",
    "        \"\"\"\n",
    "        Standard one generation GA pipeline\n",
    "        \"\"\"\n",
    "        self.population_manager.train()\n",
    "        train_fitness = self.problem.evaluate_population(self.population_manager,\n",
    "                                                         use_freshness=self.ga_args.use_freshness, update_manager=True,\n",
    "                                                         train=True)\n",
    "        self.population_manager = self.selection_fn.select_all(self.population_manager,\n",
    "                                                          self.crossover_fn.mates_per_crossover,\n",
    "                                                          self.crossover_fn.children_per_crossover)\n",
    "        self.population_manager = self.crossover_fn.crossover_pop(self.population_manager)\n",
    "        self.population_manager = self.mutation_fn.mutate_pop(self.population_manager)\n",
    "        return train_fitness\n",
    "\n",
    "    def train(self, test: bool = True,\n",
    "              callbacks: List[Callable] = None,\n",
    "              display_train_metrics: bool = True,\n",
    "              display_test_metrics: bool = True):\n",
    "        \"\"\"Call to begin the training process of the population using the arguments stored in this SimpleGA object.\n",
    "\n",
    "        Args:\n",
    "            test:\n",
    "            callbacks:\n",
    "            display_train_metrics:\n",
    "            display_test_metrics:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        print(f\"Genome size: {self.population_manager.get_gene_count():.3e} params\")\n",
    "\n",
    "        print_dict_highlighted(vars(self.ga_args))\n",
    "\n",
    "        if callbacks is None:\n",
    "            callbacks = []\n",
    "\n",
    "        for generation in range(self.ga_args.generations):\n",
    "            train_fitness = self.train_one_generation()\n",
    "            print(f\"Generation {generation}: fitness = {train_fitness}\")\n",
    "            for callback in callbacks:\n",
    "                callback(generation)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the <code>train</code> method, we have a simple loop over the generations where for each generation we call another method <code>train_one_generation</code>. <code>train_one_generation</code> implements the standard one generation GA pipeline.\n",
    "As you can notice, the different operators are called with the <code>population_manager</code> as an argument. In Gaggle's structure, the population manager holds and manages the population of individuals to evolve. In a way, it's a fancy datastructure with a couple of additional functionalities.\n",
    "\n",
    "So the standard simple ga pipeline goes like this:\n",
    "- get the population's fitness by evaluating the population\n",
    "- perform selection\n",
    "- perform crossover\n",
    "- perform mutation\n",
    "- return the fitness\n",
    "\n",
    "When implementing you own GA, you can obviously play around and change the order of the operators, ignore some operators, add some extra ones etc...\n",
    "\n",
    "Whenever you implement a new GA, you can register it in the GAFactory as shown below.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'simple': <class 'gaggle.ga.simple_ga.SimpleGA'>}\n",
      "{'simple': <class 'gaggle.ga.simple_ga.SimpleGA'>, 'custom_simple_ga': <class '__main__.SimpleGA'>}\n"
     ]
    }
   ],
   "source": [
    "from gaggle.ga import GAFactory\n",
    "\n",
    "print(GAFactory.gas)\n",
    "GAFactory.update(\"custom_simple_ga\", SimpleGA)\n",
    "print(GAFactory.gas)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll now go over population manager as it'll be helpful to understand how the operators operate on the population.\n",
    "\n",
    "### Population Manager\n",
    "<a id='population_manager'></a>\n",
    "\n",
    "The Population Manager is a data structure that holds 3 main attributes and allows for the operators to communicate with each other while maintaining a simple API.\n",
    "The 3 main attributes are:\n",
    "- <code>population</code>: a python dictionary that stores the population of individuals where the key is the individual's unique id. Ids are typically <code>[0, 1, 2, ..., ga_args.population_size - 1]</code>. So we have <code>{id: Individual}</code>.\n",
    "- <code>fitness</code>: a dictionary that stores key-value pairs of individual id and their fitness.\n",
    "- <code>fresh</code>: a dictionary that stores key-value pairs of individual id and their freshness.\n",
    "\n",
    "Freshness represents whether the fitness has already been computed since the model was last changed or not. We say a model is fresh if its fitness has not yet been updated and we say it is not fresh otherwise.\n",
    "This is used when evaluating fitness to save time, as only fresh models have their fitness computed. This is relevant when things like elitism are used, since some models survive unchanged and therefore don't need to have their fitness recomputed. Freshness is optional and can be turned off by setting <code>use_freshness</code> to <code>False</code>.\n",
    "\n",
    "Then we have the different buffers that the operators can use to communicate with one another:\n",
    "- <code>protected</code>: a list that stores ids of individuals to be protected. In this case, protected means that the individuals are to survive this generation unscathed. This is what would be used to implement elitism, where the top performers are added to the list of protected models and therefore always make it to the next generation unmodified.\n",
    "- <code>parents</code>: stores the parents selected during the selection operator. It stores it as a list of unique id (even if the parents appears multiple times during the selection process). This should be used to check if an individual is a parent but not be used to actually perform the crossovers. Instead, <code>mating_tuples</code> should be used for that.\n",
    "- <code>mating_tuples</code>: a list that stores tuples of individual ids. Selection should generate this list of tuples of ids where each tuple represents the parents for a single breeding. This list of tuples is then used by the crossover operator to generate the new population where each individual is bread from a tuple (excluding the protected members).\n",
    "- <code>to_mutate</code>: list of individual ids that stores which individuals should be affected by the mutation operator. This should be set usually by the crossover operator. Depending on whether <code>ga_args.mutate_protected</code> is set to True or not, the protected models can also be mutated.\n",
    "\n",
    "We will now go over each type of operator and how they should work with/update those buffers and attributes. But first we need to specify that in case a custom operator requires an extra buffer for communication across operators, there are <code>create_buffer</code>, <code>get_buffer</code> and <code>update_buffer</code> methods in the population manager that allow for custom buffers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selection\n",
    "<a id='selection'></a>\n",
    "\n",
    "Since it usually happens at the start of the pipeline, we'll start with selection! Below I copy-pasted the code for the base Selection object and I'll explain after."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import copy\n",
    "from abc import abstractmethod\n",
    "\n",
    "from gaggle.arguments.ga_args import GAArgs\n",
    "from gaggle.population.population_manager import PopulationManager\n",
    "\n",
    "\n",
    "class Selection:\n",
    "    r\"\"\" The parent class for any Selection Operator.\n",
    "    It gives functions to select the protected (elitism) set and to select the parents for crossover.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, ga_args: GAArgs = None):\n",
    "        self.ga_args = ga_args if ga_args is not None else GAArgs()\n",
    "        self.num_parents = ga_args.num_parents\n",
    "\n",
    "    def select_protected(self, manager: PopulationManager) -> PopulationManager:\n",
    "        \"\"\" By default, the select protected is elitism, to turn off elitism, set elitism to 0. in ga_args.\"\"\"\n",
    "        elitism = self.ga_args.elitism\n",
    "        num_to_protect = int(elitism * manager.population_size)\n",
    "\n",
    "        # we now do a topk selection process\n",
    "        fitness = copy.deepcopy(manager.get_fitness())\n",
    "\n",
    "        topk_indices = []\n",
    "        for i in range(num_to_protect):\n",
    "            best_idx = max(fitness, key=fitness.get)\n",
    "            topk_indices.append(best_idx)\n",
    "            fitness.pop(best_idx)\n",
    "\n",
    "        manager.update_protected(new_protected=topk_indices)\n",
    "\n",
    "        return manager\n",
    "\n",
    "    @abstractmethod\n",
    "    def select_parents(self, manager: PopulationManager, mates_per_crossover: int, children_per_crossover: int) -> PopulationManager:\n",
    "        \"\"\" Should select both the parents and the mating tuples \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def select_all(self, manager: PopulationManager, mates_per_crossover: int, children_per_crossover: int) -> PopulationManager:\n",
    "        \"\"\"Calls both the protoected and parent selection fucntions\"\"\"\n",
    "        manager = self.select_protected(manager)\n",
    "        manager = self.select_parents(manager, mates_per_crossover, children_per_crossover)\n",
    "        return manager\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A selection operator is always needs at least the <code>GAArgs</code> to be initialized. Although if none is given, it will take the default values for it.\n",
    "\n",
    "It has three methods, one of which is abstract and needs to be implemented for specific Selections. The other two can be modified if necessary to induce custom behavior, however their default behavior should work well enough for most applications.\n",
    "I will go over them in order.\n",
    "\n",
    "- <code>select_protected</code> has implements fitness-based elitism by default. It uses <code>ga_args.elitism</code> as the percentage of the best performing individuals to protect for the next generation. This can be changed to implement other kinds of elitisms or protection-based behaviors. If using the default implementation, all that needs to be done to turn off elitism is to set <code>ga_args.elitism</code> to 0.\n",
    "- <code>select_all</code> is just a wrapper that calls both <code>select_protected</code> and <code>select_parents</code> to give a one-line interface for the GA.\n",
    "- <code>select_parents</code> is where we set the <code>manager.mating_tuples</code> and <code>manager.parents</code> lists. This lets the crossover operator know what to crossover over. Below is an example of an implementation for a custom selection where we implement a standard roulette wheel selection where each individual's likehood of being selected is proportional to their fitness. This selection is also available by default with Gaggle as \"weighted\" for <code>ga_args.selection</code>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "\n",
    "\n",
    "class WeightedSelection(Selection):\n",
    "    r\"\"\"Standard Roulette Wheel selection\n",
    "    Probability of selection is fittness/total fittness\n",
    "    If negative fittness all fittness values are shifted to make positive\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, ga_args: GAArgs = None):\n",
    "        super(WeightedSelection, self).__init__(ga_args=ga_args)\n",
    "\n",
    "    def select_parents(self, manager: PopulationManager, mates_per_crossover: int, children_per_crossover: int) -> PopulationManager:\n",
    "        fitness = copy.deepcopy(manager.get_fitness())\n",
    "        min_fit = min(fitness.items(), key=lambda x: x[1])[1]\n",
    "        if min_fit < 0:\n",
    "            offset = np.abs(min_fit)\n",
    "            for key in fitness.keys():\n",
    "                fitness[key] += offset\n",
    "        p = []\n",
    "        fitness_sum = 0.\n",
    "        for key in fitness.keys():\n",
    "            fitness_sum += fitness[key]\n",
    "\n",
    "        ids = list(range(manager.population_size))\n",
    "        for key in ids:\n",
    "            fitness[key] /= fitness_sum\n",
    "            p.append(fitness[key])\n",
    "\n",
    "        protected_models = manager.get_protected()\n",
    "        num_protected = len(protected_models)\n",
    "        num_matings = (self.ga_args.population_size - num_protected) // children_per_crossover\n",
    "\n",
    "        mating_tuples = []\n",
    "        parents = []\n",
    "        for j in range(num_matings):\n",
    "            mating_tuple = tuple(choice(ids, size=(mates_per_crossover,), replace=False, p=p))\n",
    "            mating_tuples.append(mating_tuple)\n",
    "            parents.extend(mating_tuple)\n",
    "\n",
    "        parents = list(np.unique(parents))\n",
    "\n",
    "        manager.update_parents(new_parents=parents)\n",
    "        manager.update_mating_tuples(mating_tuples)\n",
    "\n",
    "        return manager"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As previously mentioned, here we make sure to update the parents and the mating tuples in the manager by calling <code>manager.update_parents(new_parents=parents)</code> and <code>manager.update_mating_tuples(mating_tuples)</code>.\n",
    "\n",
    "To compute the selection, we get the models' fitnesses by calling <code>manager.get_fitness()</code>\n",
    "\n",
    "It's also worth noting that we assume the selection will get the number of mates per crossover and the number of childrens per crossover from the GA (we'll see where we get those values soon when we look at Crossovers). This allows us to compute how many mating tuples we need to generate while also taking into account how many protected models there also are.\n",
    "<code>\n",
    "        protected_models = manager.get_protected()\n",
    "        num_protected = len(protected_models)\n",
    "        num_matings = (self.ga_args.population_size - num_protected) // children_per_crossover\n",
    "</code>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Crossover\n",
    "<a id='crossover'></a>\n",
    "\n",
    "Similarly to Selection, I'll go over the basic Crossover class. I'll explain each of the methods and then we'll look at a specific implementation to see how to implement your own Crossover.\n",
    "\n",
    "Below is the code for the basic Crossover class."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from abc import abstractmethod\n",
    "\n",
    "from gaggle.population.individual import Individual\n",
    "from gaggle.arguments.ga_args import GAArgs\n",
    "from gaggle.population.population_manager import PopulationManager\n",
    "\n",
    "\n",
    "class Crossover:\n",
    "    r\"\"\" The parent class for any Crossover Operator.\n",
    "    It gives a basic function to crossover a whole population once the function for crossing over a single pair of parents is specified\n",
    "\n",
    "    \"\"\"\n",
    "    mates_per_crossover = 0\n",
    "    children_per_crossover = 0\n",
    "\n",
    "    def __init__(self, ga_args: GAArgs = None):\n",
    "        self.ga_args = ga_args if ga_args is not None else GAArgs()\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def crossover_individual(self, individuals: list[Individual]) -> list[Individual]:\n",
    "        r\"\"\"Speficies how to create children from parents\n",
    "        Args:\n",
    "            individuals: a list of parents to crossover (typically 2)\n",
    "        Returns:\n",
    "            A list of children created from the parents (typically 2)\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def crossover_pop(self, manager: PopulationManager) -> PopulationManager:\n",
    "        r\"\"\" Calls the crossover indivual operator over the whole popualtion\n",
    "        while maintaining the protected parents\n",
    "        For each pair of parents, crossover is called with probability ga_args.parent_survival_rate\n",
    "        Args:\n",
    "            manager: PopulationManager object holding the current population\n",
    "        Returns:\n",
    "            Modified PopulationManager object\"\"\"\n",
    "        parents = manager.get_parents()\n",
    "        num_parents = len(parents)\n",
    "        population = manager.get_population()\n",
    "        freshness = manager.get_freshness()\n",
    "\n",
    "        new_population = {}\n",
    "        new_freshness = {}\n",
    "\n",
    "        free_indices = list(range(self.ga_args.population_size))\n",
    "        to_mutate = []\n",
    "\n",
    "        # first we get the protected indices and we add them to the list\n",
    "        protected_models = manager.get_protected()\n",
    "\n",
    "        # adding the protected\n",
    "        for p in protected_models:\n",
    "            new_population[p] = population[p]\n",
    "            new_freshness[p] = freshness[p]\n",
    "            free_indices.remove(p)\n",
    "            if self.ga_args.mutate_protected:\n",
    "                to_mutate.append(p)\n",
    "\n",
    "        mating_tuples = manager.get_mating_tuples()\n",
    "        surviving_parents = []\n",
    "        to_mate = []\n",
    "        # now we count how many parents to keep\n",
    "        for mating_tuple in mating_tuples:\n",
    "            # probability to keep the parents rather than the children\n",
    "            keep_parents = random.random() < self.ga_args.parent_survival_rate\n",
    "            if keep_parents:\n",
    "                surviving_parents.extend(mating_tuple)\n",
    "            else:\n",
    "                to_mate.append(mating_tuple)\n",
    "\n",
    "        # we now fill the lucky parents that survived\n",
    "        for idx in surviving_parents:\n",
    "            if idx in free_indices:\n",
    "                new_population[idx] = copy.deepcopy(population[idx])  # we might have put that model already in so we don't want a double reference\n",
    "                new_freshness[idx] = freshness[idx]\n",
    "                free_indices.remove(idx)\n",
    "                to_mutate.append(idx)\n",
    "            else:\n",
    "                for new_idx in free_indices:\n",
    "                    if new_idx in surviving_parents:\n",
    "                        continue\n",
    "                    new_population[new_idx] = copy.deepcopy(population[idx])  # we might have put that model already in so we don't want a double reference\n",
    "                    new_freshness[new_idx] = freshness[idx]\n",
    "                    free_indices.remove(new_idx)\n",
    "                    to_mutate.append(new_idx)\n",
    "                    break\n",
    "\n",
    "        # now we can do the actual crossover\n",
    "        for mating_tuple in to_mate:\n",
    "            party = [manager.population[idx] for idx in mating_tuple]\n",
    "            children = self.crossover_individual(copy.deepcopy(party))\n",
    "            for child in children:\n",
    "                new_idx = free_indices.pop(0)\n",
    "                to_mutate.append(new_idx)\n",
    "                new_population[new_idx] = child\n",
    "                new_freshness[new_idx] = True\n",
    "\n",
    "        # if we are missing some, we fill the population\n",
    "        for i in free_indices:\n",
    "            idx = parents[random.randint(0, num_parents - 1)]\n",
    "            new_population[i] = copy.deepcopy(population[idx])  # we might have put that model already in so we don't want a double reference\n",
    "            new_freshness[i] = freshness[idx]\n",
    "            free_indices.remove(i)\n",
    "            to_mutate.append(i)\n",
    "\n",
    "        # we finally update the manager\n",
    "        manager.update_population(new_population, new_freshness)\n",
    "        manager.update_to_mutate(new_to_mutate=to_mutate)\n",
    "        return manager\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, this one is a bit more complex than the basic selection. What's nice is you'll most likely won't have to touch the complicated <code>crossover_pop</code> method as all it does is fill the available population spots in order of priority.\n",
    "We can summarize its behavior as follows:\n",
    "- It first takes the protected models and adds them to the new population. That guarantees that the protected models always have space to be put into the population. The protected members also get to keep their previous id.\n",
    "- Then, from the mating tuples it gets from <code>manager.get_mating_tuples()</code> (the ones generated by the selection), it sees using <code>ga_args.parent_survival_rate</code> whether each tuple of parents mates or survives instead of their children.\n",
    "- It then adds the surviving parents to the population (while trying to preserve the ids as much as possible).\n",
    "- Now, we can do the crossover, and we fill in the spots using the tuples of parents that didn't get chosen to survive instead of their children\n",
    "- Finally, in case of some user mis-inputs or mis-calculations with <code>mates_per_crossover</code> or <code>children_per_crossover</code>, we fill in potential missing spots in the population. This avoids having indices in the population with no individuals since we want a fixed population size. To do so we just heuristically select one of the parents at random per spot left. This code usually is never run but is there as a safety net.\n",
    "- Finally, we update the manager with the new population, freshness and the list of models to mutate using:\n",
    "\n",
    "<code>\n",
    "manager.update_population(new_population, new_freshness)\n",
    "\n",
    "manager.update_to_mutate(new_to_mutate=to_mutate)\n",
    "</code>\n",
    "\n",
    "Notice how I <code>mates_per_crossover</code> and <code>children_per_crossover</code> are stored as class variables. This is because they are supposed to be fixed for each different Crossover and they are inherent to their particular Crossover.\n",
    "The GA can get the value from the class and give it to the Selection so that the Selection can generate the appropriate number of mating tuples.\n",
    "\n",
    "Now in practice, all you have to do to implement your own Crossover is implement the <code>crossover_individual</code> method. It takes in a list of individuals and returns the list of children individuals generated by the crossover. Below is an example using the k_point crossover."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from gaggle.population.individual import Individual\n",
    "from gaggle.operators.crossover.crossover import Crossover\n",
    "from gaggle.arguments.ga_args import GAArgs\n",
    "from gaggle.utils.individual_helper import from_gene_pool, from_tensor\n",
    "\n",
    "import torch\n",
    "from numpy.random import default_rng\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class KPointCrossover(Crossover):\n",
    "    r\"\"\"Generalization of single point crossover to k points\n",
    "    See the following tutorial for a more in depth description\n",
    "    https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_crossover.htm\n",
    "    Generates two children from two parents\n",
    "    \"\"\"\n",
    "    mates_per_crossover = 2\n",
    "    children_per_crossover = 2\n",
    "\n",
    "    def __init__(self, ga_args: GAArgs = None):\n",
    "        super(KPointCrossover, self).__init__(ga_args=ga_args)\n",
    "\n",
    "    def crossover_individual(self, individuals: list[Individual]) ->list[Individual]:\n",
    "        assert len(individuals) == self.mates_per_crossover\n",
    "        individual_1, individual_2 = individuals\n",
    "        assert individual_1.get_genome_size() == individual_2.get_genome_size()\n",
    "        assert individual_1.sys_args.device == individual_2.sys_args.device\n",
    "        genome_size = individual_1.get_genome_size()\n",
    "\n",
    "        genome_1 = individual_1.get_gene_pool()\n",
    "        genome_2 = individual_2.get_gene_pool()\n",
    "\n",
    "        # convert to a singular tensor\n",
    "        tensor_1, metadata_1 = from_gene_pool(genome_1)\n",
    "        tensor_2, metadata_2 = from_gene_pool(genome_2)\n",
    "\n",
    "        k = self.ga_args.k_point\n",
    "\n",
    "        # select a set of k random indices without repeats\n",
    "        rng = default_rng()\n",
    "        cut_indices = np.sort(rng.choice(genome_size+1, size=k, replace=False))\n",
    "        flip = True\n",
    "        last_cut = 0\n",
    "        for cut_idx in cut_indices:\n",
    "            if flip:\n",
    "                data_1 = tensor_1[last_cut:cut_idx].clone().detach()\n",
    "                tensor_1[last_cut: cut_idx] = tensor_2[last_cut:cut_idx].clone().detach()\n",
    "                tensor_2[last_cut: cut_idx] = data_1\n",
    "\n",
    "            last_cut = cut_idx\n",
    "            flip = not flip\n",
    "\n",
    "        # don't forget the last one\n",
    "        if flip:\n",
    "            data_1 = tensor_1[last_cut:].clone().detach()\n",
    "            tensor_1[last_cut:] = tensor_2[last_cut:].clone().detach()\n",
    "            tensor_2[last_cut:] = data_1\n",
    "\n",
    "        from_tensor(gene_pool=genome_1, tensor=tensor_1, metadata=metadata_1)\n",
    "        from_tensor(gene_pool=genome_2, tensor=tensor_2, metadata=metadata_2)\n",
    "\n",
    "        return [individual_1, individual_2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "No need to interact with the manager here since it's done in <code>crossover_pop</code>."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mutation\n",
    "<a id='mutation'></a>\n",
    "\n",
    "Now that we've covered Crossovers, we can finally look at mutations. Similarly to the other operators, I'll give the code for the base implementation of the Mutation class and we'll cover what needs to be done to create your own Mutation.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "from gaggle.population.individual import Individual\n",
    "from gaggle.arguments.ga_args import GAArgs\n",
    "from gaggle.population.population_manager import PopulationManager\n",
    "\n",
    "\n",
    "class Mutation:\n",
    "    r\"\"\" The parent class for any Mutation Operator.\n",
    "    It gives a basic function to mutate a whole population once the function for mutating a single individual is specified\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, ga_args: GAArgs = None):\n",
    "        self.ga_args = ga_args if ga_args is not None else GAArgs()\n",
    "\n",
    "    @abstractmethod\n",
    "    def mutate_individual(self, individual: Individual) -> Individual:\n",
    "        r\"\"\"Speficies how to mutate a single individual\n",
    "        Args:\n",
    "            individuals: a single individual to mutate\n",
    "        Returns:\n",
    "            A single individual after mutation\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def mutate_pop(self, manager: PopulationManager) -> PopulationManager:\n",
    "        r\"\"\" Calls the mutate_individual function for each member of the population\n",
    "        Args:\n",
    "            manager: PopulationManager object holding the current population\n",
    "        Returns:\n",
    "            Modified PopulationManager object\"\"\"\n",
    "        population = manager.get_population()\n",
    "        new_freshness = manager.get_freshness()\n",
    "\n",
    "        to_mutate = manager.get_to_mutate()\n",
    "        for individual_idx in to_mutate:\n",
    "            population[individual_idx] = self.mutate_individual(population[individual_idx])\n",
    "            new_freshness[individual_idx] = True\n",
    "\n",
    "        manager.update_population(population, new_freshness)\n",
    "        # in case we need to enforce parameter value bounds on the freshly mutated samples. Since it only applies to\n",
    "        # mutated samples we don't have to update the freshness\n",
    "        manager.apply_bounds(to_mutate)\n",
    "        return manager\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similarly to crossover, we have <code>mutate_pop</code> and <code>mutate_individual</code>. Here in this case <code>mutate_pop</code> just iterates through the list of indices to be mutated that it gets from the manager (using <code> manager.get_to_mutate()</code>) and that should have been set by the Crossover. We then call <code>mutate_individual</code> on each of the individuals in a loop and update the population with the mutated population in the manager using <code>manager.update_population(population, new_freshness)</code>\n",
    "\n",
    "We finally need to make another call to the manager to apply weight bounds restrictions. In cases where we want limits on the possible gene values, this ensures that the mutated population stays within the bounds and therefore should be also called whenever you implement your own <code>mutate_pop</code>. It is in general not recommended to modify <code>mutate_pop</code> unless absolutely necessary.\n",
    "\n",
    "Most Mutations can be implemented by just implementing your own <code>mutate_individual</code> that should return the mutated individual. Below is an example with the uniform mutation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from gaggle.population.base_individuals.nn_individual import Individual\n",
    "from gaggle.operators.mutation.mutation import Mutation\n",
    "from gaggle.arguments.ga_args import GAArgs\n",
    "\n",
    "\n",
    "class UniformMutation(Mutation):\n",
    "    r\"\"\"For real valued chromosomes\n",
    "    Adds noise from a Uniform distribution within the range specified by:\n",
    "    ga_args.uniform_mutation_min_val and ga_args.uniform_mutation_max_val\n",
    "    Noise is only added to each gene with probability specified by ga_args.mutation_chance\n",
    "    \"\"\"\n",
    "    def __init__(self, ga_args: GAArgs = None):\n",
    "        super(UniformMutation, self).__init__(ga_args)\n",
    "        self.uniform_mutation_min_val = self.ga_args.uniform_mutation_min_val\n",
    "        self.uniform_mutation_max_val = self.ga_args.uniform_mutation_max_val\n",
    "\n",
    "    def mutate_individual(self, individual: Individual) -> Individual:\n",
    "        genome = individual.get_gene_pool()\n",
    "        num_chromosomes = len(genome.keys())\n",
    "        for i in range(num_chromosomes):\n",
    "            # generate the random mask\n",
    "            mask = torch.rand(genome[i][\"param\"].data.size(), dtype=torch.float,\n",
    "                                device=genome[i][\"param\"].data.device) < self.ga_args.mutation_chance\n",
    "            indices = torch.nonzero(mask, as_tuple=True)\n",
    "            scaled_mutation = (torch.rand(size=genome[i][\"param\"].data[indices].size(), device=genome[i][\"param\"].data.device) *\n",
    "                       (self.uniform_mutation_max_val - self.uniform_mutation_min_val)) - self.uniform_mutation_min_val\n",
    "            genome[i][\"param\"].data[indices] += scaled_mutation\n",
    "        return individual\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Registering Custom Operators\n",
    "<a id='registering_custom_operators'></a>\n",
    "\n",
    "Finally, I'll go over how to register custom operators to their respective factories so that they can be used with your basic original training script and your configuration files.\n",
    "\n",
    "Similarly to how problems are registered in the problem, dataset and environment factories; operators have to be registered in the respective factories to be fully incorporated in our framework as if they were one of the base operators.\n",
    "\n",
    "Below will be examples on how to register a custom operator for each of the operators"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'truncation': <class 'gaggle.operators.selection.base_selections.truncation_selection.TruncationSelection'>, 'weighted': <class 'gaggle.operators.selection.base_selections.weighted_selection.WeightedSelection'>, 'relative_weighted': <class 'gaggle.operators.selection.base_selections.relative_weighted_selection.RelativeWeightedSelection'>, 'probabilistic_tournament': <class 'gaggle.operators.selection.base_selections.probabilistic_tournament_selection.ProbabilisticTournamentSelection'>, 'simple_tournament': <class 'gaggle.operators.selection.base_selections.simple_tournament_selection.SimpleTournamentSelection'>}\n",
      "{'truncation': <class 'gaggle.operators.selection.base_selections.truncation_selection.TruncationSelection'>, 'weighted': <class 'gaggle.operators.selection.base_selections.weighted_selection.WeightedSelection'>, 'relative_weighted': <class 'gaggle.operators.selection.base_selections.relative_weighted_selection.RelativeWeightedSelection'>, 'probabilistic_tournament': <class 'gaggle.operators.selection.base_selections.probabilistic_tournament_selection.ProbabilisticTournamentSelection'>, 'simple_tournament': <class 'gaggle.operators.selection.base_selections.simple_tournament_selection.SimpleTournamentSelection'>, 'custom_weighted_selection': <class '__main__.WeightedSelection'>}\n",
      "{'uniform': <class 'gaggle.operators.crossover.base_crossovers.uniform_crossover.UniformCrossover'>, 'k_point': <class 'gaggle.operators.crossover.base_crossovers.k_point_crossover.KPointCrossover'>}\n",
      "{'uniform': <class 'gaggle.operators.crossover.base_crossovers.uniform_crossover.UniformCrossover'>, 'k_point': <class 'gaggle.operators.crossover.base_crossovers.k_point_crossover.KPointCrossover'>, 'custom_k_point_crossover': <class '__main__.KPointCrossover'>}\n",
      "{'normal': <class 'gaggle.operators.mutation.base_mutations.normal_mutation.NormalMutation'>, 'uniform': <class 'gaggle.operators.mutation.base_mutations.uniform.UniformMutation'>}\n",
      "{'normal': <class 'gaggle.operators.mutation.base_mutations.normal_mutation.NormalMutation'>, 'uniform': <class 'gaggle.operators.mutation.base_mutations.uniform.UniformMutation'>, 'custom_uniform_mutation': <class '__main__.UniformMutation'>}\n"
     ]
    }
   ],
   "source": [
    "from gaggle.operators import SelectionFactory, CrossoverFactory, MutationFactory\n",
    "\n",
    "# registering the Selection\n",
    "print(SelectionFactory.selections)\n",
    "SelectionFactory.update(\"custom_weighted_selection\", WeightedSelection)\n",
    "print(SelectionFactory.selections)\n",
    "\n",
    "# registering the Crossover\n",
    "print(CrossoverFactory.crossovers)\n",
    "CrossoverFactory.update(\"custom_k_point_crossover\", KPointCrossover)\n",
    "print(CrossoverFactory.crossovers)\n",
    "\n",
    "# registering the Mutation\n",
    "print(MutationFactory.mutations)\n",
    "MutationFactory.update(\"custom_uniform_mutation\", UniformMutation)\n",
    "print(MutationFactory.mutations)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}